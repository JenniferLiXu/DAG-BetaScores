# To avoid numerical issues, subtract the max score before exponentiating
max_score <- max(differ_score)
exp_scores <- exp(differ_score - max_score)
# Normalize the exponentiated scores to get the importance weights
importance_weights <- exp_scores / sum(exp_scores)
cat("importance_weights", ":" , importance_weights, "\n")
ess_value <- 1 / sum(importance_weights^2)
cat("ess_value", ":" , ess_value, "\n")
return(list(importance_weights = importance_weights, ess_value = ess_value))
}
#start with empty graph or user defined graph  or from other algo. and learn the beta matrix
starting_dag <- list(matrix(c(0), nrow = 14, ncol = 14, byrow = TRUE))
betas_init <- calculateBetaScoresArray(starting_dag, k = 1 ,n)[,,1]
# Number of iterations
iter <- 1
weighted_betas <- list(betas_init)
averaged_beta_ess <- numeric(iter)
ess_DAGs <- numeric(iter)
DAG_scores <- list()
# Threshold
epsilon <- 10  # Define a threshold for individual differences
num_steps <- 5  # Number of steps to consider for fluctuation
difference_threshold <- 1  # Define a threshold for the standard deviation of differences
differences <- numeric()  # Initialize a vector to store the last 'num_steps' differences
# Looping
for (i in 1:iter) {
example <- orderMCMC_betas(n,startorder = permy,iterations = 100,
betas = weighted_betas[[i]],
stepsave = 10, moveprobs)
DAGs <- example[[1]]
DAG_scores[[i]] <-example[[2]]
beta_values <- calculateBetaScoresArray(DAGs, k = length(DAGs) ,n) #a list of matrices
### Update beta matrix using importance sampling
#is_results <- importance_DAG(DAGs = DAGs, betas = beta_values)
is_results <- importance_DAGg_prev(DAGs = DAGs, betas = DAG_scores[[i]])
# Vectorized multiplication of each matrix by its corresponding weight
# and then summing up the matrices
weights <- is_results$importance_weights
#cat("weights",i, ":" , weights, "\n")
weighted_betas[[i + 1]]  <- Reduce("+", lapply(1:length(weights),
function(k) beta_values[,,k] * weights[k]))
ess_DAGs[i] <-is_results$ess_value
### Stopping criteria for beta matrix convergence
# Calculate the Frobenius norm of the difference between current and previous matrices
current_beta_matrix <- weighted_betas[[i + 1]]
previous_beta_matrix <- weighted_betas[[i]]
# # Calculate difference only for non-NA pairs. Replace NA with 0 or other appropriate value
current_beta_matrix[is.na(current_beta_matrix)] <- 0
previous_beta_matrix[is.na(previous_beta_matrix)] <- 0
# Calculate difference using Frobenius norm
difference <- norm(current_beta_matrix - previous_beta_matrix, type = "F")
# Update the differences vector
differences <- c(differences, difference)
if(all(differences < epsilon) && sd(differences[(i-num_steps): i]) < difference_threshold) {
cat("Convergence achieved based on fluctuation criterion.\n")
break
}
### Update the order for the next iteration
permy <- unlist(example[[4]][length(example[[4]])])
}
DAG_scores[[i]]
#start with empty graph or user defined graph  or from other algo. and learn the beta matrix
starting_dag <- list(matrix(c(0), nrow = 14, ncol = 14, byrow = TRUE))
betas_init <- calculateBetaScoresArray(starting_dag, k = 1 ,n)[,,1]
# Number of iterations
iter <- 1
weighted_betas <- list(betas_init)
averaged_beta_ess <- numeric(iter)
ess_DAGs <- numeric(iter)
DAG_scores <- list()
# Threshold
epsilon <- 10  # Define a threshold for individual differences
num_steps <- 5  # Number of steps to consider for fluctuation
difference_threshold <- 1  # Define a threshold for the standard deviation of differences
differences <- numeric()  # Initialize a vector to store the last 'num_steps' differences
# Looping
for (i in 1:iter) {
example <- orderMCMC_betas(n,startorder = permy,iterations = 100,
betas = weighted_betas[[i]],
stepsave = 10, moveprobs)
DAGs <- example[[1]]
DAG_scores[[i]] <-example[[2]]
beta_values <- calculateBetaScoresArray(DAGs, k = length(DAGs) ,n) #a list of matrices
### Update beta matrix using importance sampling
#is_results <- importance_DAG(DAGs = DAGs, betas = beta_values)
is_results <- importance_DAGg_prev(DAGs = DAGs, betas = unlist(DAG_scores[[i]]))
# Vectorized multiplication of each matrix by its corresponding weight
# and then summing up the matrices
weights <- is_results$importance_weights
#cat("weights",i, ":" , weights, "\n")
weighted_betas[[i + 1]]  <- Reduce("+", lapply(1:length(weights),
function(k) beta_values[,,k] * weights[k]))
ess_DAGs[i] <-is_results$ess_value
### Stopping criteria for beta matrix convergence
# Calculate the Frobenius norm of the difference between current and previous matrices
current_beta_matrix <- weighted_betas[[i + 1]]
previous_beta_matrix <- weighted_betas[[i]]
# # Calculate difference only for non-NA pairs. Replace NA with 0 or other appropriate value
current_beta_matrix[is.na(current_beta_matrix)] <- 0
previous_beta_matrix[is.na(previous_beta_matrix)] <- 0
# Calculate difference using Frobenius norm
difference <- norm(current_beta_matrix - previous_beta_matrix, type = "F")
# Update the differences vector
differences <- c(differences, difference)
if(all(differences < epsilon) && sd(differences[(i-num_steps): i]) < difference_threshold) {
cat("Convergence achieved based on fluctuation criterion.\n")
break
}
### Update the order for the next iteration
permy <- unlist(example[[4]][length(example[[4]])])
}
#start with empty graph or user defined graph  or from other algo. and learn the beta matrix
starting_dag <- list(matrix(c(0), nrow = 14, ncol = 14, byrow = TRUE))
betas_init <- calculateBetaScoresArray(starting_dag, k = 1 ,n)[,,1]
# Number of iterations
iter <- 10
weighted_betas <- list(betas_init)
averaged_beta_ess <- numeric(iter)
ess_DAGs <- numeric(iter)
DAG_scores <- list()
# Threshold
epsilon <- 10  # Define a threshold for individual differences
num_steps <- 5  # Number of steps to consider for fluctuation
difference_threshold <- 1  # Define a threshold for the standard deviation of differences
differences <- numeric()  # Initialize a vector to store the last 'num_steps' differences
# Looping
for (i in 1:iter) {
example <- orderMCMC_betas(n,startorder = permy,iterations = 100,
betas = weighted_betas[[i]],
stepsave = 10, moveprobs)
DAGs <- example[[1]]
DAG_scores[[i]] <-example[[2]]
beta_values <- calculateBetaScoresArray(DAGs, k = length(DAGs) ,n) #a list of matrices
### Update beta matrix using importance sampling
#is_results <- importance_DAG(DAGs = DAGs, betas = beta_values)
is_results <- importance_DAGg_prev(DAGs = DAGs, betas = unlist(DAG_scores[[i]]))
# Vectorized multiplication of each matrix by its corresponding weight
# and then summing up the matrices
weights <- is_results$importance_weights
#cat("weights",i, ":" , weights, "\n")
weighted_betas[[i + 1]]  <- Reduce("+", lapply(1:length(weights),
function(k) beta_values[,,k] * weights[k]))
ess_DAGs[i] <-is_results$ess_value
### Stopping criteria for beta matrix convergence
# Calculate the Frobenius norm of the difference between current and previous matrices
current_beta_matrix <- weighted_betas[[i + 1]]
previous_beta_matrix <- weighted_betas[[i]]
# # Calculate difference only for non-NA pairs. Replace NA with 0 or other appropriate value
current_beta_matrix[is.na(current_beta_matrix)] <- 0
previous_beta_matrix[is.na(previous_beta_matrix)] <- 0
# Calculate difference using Frobenius norm
difference <- norm(current_beta_matrix - previous_beta_matrix, type = "F")
# Update the differences vector
differences <- c(differences, difference)
if(all(differences < epsilon) && sd(differences[(i-num_steps): i]) < difference_threshold) {
cat("Convergence achieved based on fluctuation criterion.\n")
break
}
### Update the order for the next iteration
permy <- unlist(example[[4]][length(example[[4]])])
}
print(ess_DAGs)
beta_matrix
beta_values
#start with empty graph or user defined graph  or from other algo. and learn the beta matrix
starting_dag <- list(matrix(c(0), nrow = 14, ncol = 14, byrow = TRUE))
betas_init <- calculateBetaScoresArray(starting_dag, k = 1 ,n)[,,1]
betas_init
#start with empty graph or user defined graph  or from other algo. and learn the beta matrix
starting_dag <- list(matrix(c(0), nrow = 14, ncol = 14, byrow = TRUE))
betas_init <- calculateBetaScoresArray(starting_dag, k = 1 ,n)[,,1]
betas_init
# Number of iterations
iter <- 100
weighted_betas <- list(betas_init)
averaged_beta_ess <- numeric(iter)
ess_DAGs <- numeric(iter)
DAG_scores <- list()
# Threshold
epsilon <- 10  # Define a threshold for individual differences
num_steps <- 5  # Number of steps to consider for fluctuation
difference_threshold <- 1  # Define a threshold for the standard deviation of differences
differences <- numeric()  # Initialize a vector to store the last 'num_steps' differences
# Looping
for (i in 1:iter) {
example <- orderMCMC_betas(n,startorder = permy,iterations = 100,
betas = weighted_betas[[i]],
stepsave = 10, moveprobs)
DAGs <- example[[1]]
DAG_scores[[i]] <-example[[2]]
beta_values <- calculateBetaScoresArray(DAGs, k = length(DAGs) ,n) #a list of matrices
### Update beta matrix using importance sampling
#is_results <- importance_DAG(DAGs = DAGs, betas = beta_values)
is_results <- importance_DAGg_prev(DAGs = DAGs, betas = unlist(DAG_scores[[i]]))
# Vectorized multiplication of each matrix by its corresponding weight
# and then summing up the matrices
weights <- is_results$importance_weights
#cat("weights",i, ":" , weights, "\n")
weighted_betas[[i + 1]]  <- Reduce("+", lapply(1:length(weights),
function(k) beta_values[,,k] * weights[k]))
ess_DAGs[i] <-is_results$ess_value
### Stopping criteria for beta matrix convergence
# Calculate the Frobenius norm of the difference between current and previous matrices
current_beta_matrix <- weighted_betas[[i + 1]]
previous_beta_matrix <- weighted_betas[[i]]
# # Calculate difference only for non-NA pairs. Replace NA with 0 or other appropriate value
current_beta_matrix[is.na(current_beta_matrix)] <- 0
previous_beta_matrix[is.na(previous_beta_matrix)] <- 0
# Calculate difference using Frobenius norm
difference <- norm(current_beta_matrix - previous_beta_matrix, type = "F")
# Update the differences vector
differences <- c(differences, difference)
if(all(differences < epsilon) && sd(differences[(i-num_steps): i]) < difference_threshold) {
cat("Convergence achieved based on fluctuation criterion.\n")
break
}
### Update the order for the next iteration
permy <- unlist(example[[4]][length(example[[4]])])
}
print(ess_DAGs)
BiDAG:::DAGcorescore
BiDAG:::DAGscore
scorepar$n
# For continuous data
scoreParam <- BiDAG::scoreparameters("bge", BiDAG::Boston)
scoreParam
scoreParam$n
scoreParam
# load the necessary functions
#source('./edgerevandstructure/newedgerevfns.R')
#source('./edgerevandstructure/newedgerevmove.R')
source('./orderMCMC_betas.R')
source('./orderscore_betas.R')
source('./samplefns-beta.R')
source('./scoring/scorefns.R')
#Use the function to calculate beta values
source('./calculateBetaScoresArray.R')
# Example: Generating a random dataset
set.seed(123)
data <- matrix(rnorm(1400), ncol = 14)  # A dataset with 14 variables
# Specify the conditional independence test
# gaussCItest is used for continuous data (assuming Gaussian distribution)
ciTest <- gaussCItest
# Apply the PC algorithm
pcFit <- pc(suffStat = list(C = cor(data), n = nrow(data)),
indepTest = ciTest, p = 14, alpha = 0.05)
# Convert the output to an adjacency matrix
adjMatrix <- as(pcFit, "amat")
#Score of a DAG with given beta matrix
DAGscore_under_betas <- function(incidence, betas){
diag(betas) <- 0
sampledscore<-0
for (child in 1:n){
for (parent in 1:n){
sampledscore <- sampledscore + betas[parent, child]*incidence[parent, child]
}
}
return(sampledscore)
}
#Importance Weights for the sampled DAGs
importance_DAG <- function(DAGs, betas){
differ_score <- numeric()
#betas = beta_values
for (i in 1:length(DAGs)){
target_score <- BiDAG::DAGscore(scoreParam, DAGs[[i]])
#cat("target_score",i, ":" , target_score, "\n")
beta_score <- DAGscore_under_betas(DAGs[[i]], betas[,,i])
#cat("beta_score",i, ":" , beta_score, "\n")
differ_score[i] <- target_score - beta_score
}
# To avoid numerical issues, subtract the max score before exponentiating
max_score <- max(differ_score)
exp_scores <- exp(differ_score - max_score)
# Normalize the exponentiated scores to get the importance weights
importance_weights <- exp_scores / sum(exp_scores)
cat("importance_weights", ":" , importance_weights, "\n")
ess_value <- 1 / sum(importance_weights^2)
cat("ess_value", ":" , ess_value, "\n")
return(list(importance_weights = importance_weights, ess_value = ess_value))
}
n <- 14
DAG_Test[[1]]
# Define the starting order
permy <- c(1:14)
# Calculate move probabilities
prob1<-99
if(n>3){ prob1<-round(6*99*n/(n^2+10*n-24)) }
prob1<-prob1/100
moveprobs<-c(prob1,0.99-prob1,0.01)
moveprobs<-moveprobs/sum(moveprobs) # normalisation
#start with empty graph or user defined graph  or from other algo. and learn the beta matrix
starting_dag <- list(matrix(c(0), nrow = 14, ncol = 14, byrow = TRUE))
betas_init <- calculateBetaScoresArray(starting_dag, k = 1 ,n)[,,1]
# Number of iterations
iter <- 100
weighted_betas <- list(betas_init)
averaged_beta_ess <- numeric(iter)
ess_DAGs <- numeric(iter)
# Number of iterations
iter <- 20
weighted_betas <- list(betas_init)
averaged_beta_ess <- numeric(iter)
ess_DAGs <- numeric(iter)
DAG_scores <- list()
# Threshold
epsilon <- 10  # Define a threshold for individual differences
num_steps <- 5  # Number of steps to consider for fluctuation
difference_threshold <- 1  # Define a threshold for the standard deviation of differences
differences <- numeric()  # Initialize a vector to store the last 'num_steps' differences
betas_init
# Looping
for (i in 1:iter) {
example <- orderMCMC_betas(n,startorder = permy,iterations = 100,
betas = weighted_betas[[i]],
stepsave = 10, moveprobs)
DAGs <- example[[1]]
DAG_scores[[i]] <-example[[2]]
beta_values <- calculateBetaScoresArray(DAGs, k = length(DAGs) ,n) #a list of matrices
### Update beta matrix using importance sampling
#is_results <- importance_DAG(DAGs = DAGs, betas = beta_values)
is_results <- importance_DAGg_prev(DAGs = DAGs, betas = unlist(DAG_scores[[i]]))
# Vectorized multiplication of each matrix by its corresponding weight
# and then summing up the matrices
weights <- is_results$importance_weights
#cat("weights",i, ":" , weights, "\n")
weighted_betas[[i + 1]]  <- Reduce("+", lapply(1:length(weights),
function(k) beta_values[,,k] * weights[k]))
ess_DAGs[i] <-is_results$ess_value
### Stopping criteria for beta matrix convergence
# Calculate the Frobenius norm of the difference between current and previous matrices
current_beta_matrix <- weighted_betas[[i + 1]]
previous_beta_matrix <- weighted_betas[[i]]
# # Calculate difference only for non-NA pairs. Replace NA with 0 or other appropriate value
current_beta_matrix[is.na(current_beta_matrix)] <- 0
previous_beta_matrix[is.na(previous_beta_matrix)] <- 0
# Calculate difference using Frobenius norm
difference <- norm(current_beta_matrix - previous_beta_matrix, type = "F")
# Update the differences vector
differences <- c(differences, difference)
if(all(differences < epsilon) && sd(differences[(i-num_steps): i]) < difference_threshold) {
cat("Convergence achieved based on fluctuation criterion.\n")
break
}
### Update the order for the next iteration
permy <- unlist(example[[4]][length(example[[4]])])
}
#This function will return a 3D array where allBetaScores[i, j, k]
#represents the beta score of parent node i on child node j in the k-th sampled DAG.
k=1
dagIndex = 1
incidence <- DAGs[[1]]
incidence
childNode <- 1
# Identify the parent nodes for this child in the current DAG
parentNodes <- which(incidence[, childNode] == 1)
parentNodes
# Calculate the score for the child with all its current parents
scoreWithAllParents <- BiDAG:::DAGcorescore(childNode, parentnodes = parentNodes, scoreParam$n, scoreParam)
scoreWithAllParents
parentNode <- 1
if (parentNode != childNode) {
# Check if parentNode is actually a parent in this DAG
if (parentNode %in% parentNodes) {
# Remove parentNode and calculate the score
WithoutparentNodes <- parentNodes[!parentNodes == parentNode]
scoreWithoutParent <- BiDAG:::DAGcorescore(childNode, parentnodes = WithoutparentNodes, scoreParam$n, scoreParam)
# Calculate beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithAllParents - scoreWithoutParent
} else {
WithparentNodes <-c(parentNode, parentNodes)
scoreWithParentNode <- BiDAG:::DAGcorescore(childNode, parentnodes = WithparentNodes, scoreParam$n, scoreParam)
# Calculate the beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithParentNode - scoreWithAllParents
# Print the scoreWithParentNode
# print(paste("Child node",childNode,
#             " has parents:",paste(parentNodes, collapse = ", "),
#             " with Added node:",parentNode,
#             " scoreWithParentNode is", scoreWithParentNode,
#             " scoreWithAllParents is", scoreWithAllParents))
}
} else {
# Beta score is not applicable for self (node cannot be its own parent)
allBetaScores[parentNode, childNode, dagIndex] <- NA
}
allBetaScores
# The array dimensions are [number of parents, number of children, number of sampled DAGs]
allBetaScores <- array(NA, dim = c(n, n, k))
childNode <- 1
# Identify the parent nodes for this child in the current DAG
parentNodes <- which(incidence[, childNode] == 1)
# Calculate the score for the child with all its current parents
scoreWithAllParents <- BiDAG:::DAGcorescore(childNode, parentnodes = parentNodes, scoreParam$n, scoreParam)
for (parentNode in 1:n) {
parentNode <- 1
if (parentNode != childNode) {
# Check if parentNode is actually a parent in this DAG
if (parentNode %in% parentNodes) {
# Remove parentNode and calculate the score
WithoutparentNodes <- parentNodes[!parentNodes == parentNode]
scoreWithoutParent <- BiDAG:::DAGcorescore(childNode, parentnodes = WithoutparentNodes, scoreParam$n, scoreParam)
# Calculate beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithAllParents - scoreWithoutParent
} else {
WithparentNodes <-c(parentNode, parentNodes)
scoreWithParentNode <- BiDAG:::DAGcorescore(childNode, parentnodes = WithparentNodes, scoreParam$n, scoreParam)
# Calculate the beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithParentNode - scoreWithAllParents
# Print the scoreWithParentNode
# print(paste("Child node",childNode,
#             " has parents:",paste(parentNodes, collapse = ", "),
#             " with Added node:",parentNode,
#             " scoreWithParentNode is", scoreWithParentNode,
#             " scoreWithAllParents is", scoreWithAllParents))
}
} else {
# Beta score is not applicable for self (node cannot be its own parent)
allBetaScores[parentNode, childNode, dagIndex] <- NA
}
}
allBetaScores
parentNode <- 2
if (parentNode != childNode) {
# Check if parentNode is actually a parent in this DAG
if (parentNode %in% parentNodes) {
# Remove parentNode and calculate the score
WithoutparentNodes <- parentNodes[!parentNodes == parentNode]
scoreWithoutParent <- BiDAG:::DAGcorescore(childNode, parentnodes = WithoutparentNodes, scoreParam$n, scoreParam)
# Calculate beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithAllParents - scoreWithoutParent
} else {
WithparentNodes <-c(parentNode, parentNodes)
scoreWithParentNode <- BiDAG:::DAGcorescore(childNode, parentnodes = WithparentNodes, scoreParam$n, scoreParam)
# Calculate the beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithParentNode - scoreWithAllParents
# Print the scoreWithParentNode
# print(paste("Child node",childNode,
#             " has parents:",paste(parentNodes, collapse = ", "),
#             " with Added node:",parentNode,
#             " scoreWithParentNode is", scoreWithParentNode,
#             " scoreWithAllParents is", scoreWithAllParents))
}
} else {
# Beta score is not applicable for self (node cannot be its own parent)
allBetaScores[parentNode, childNode, dagIndex] <- NA
}
allBetaScores
WithparentNodes
scoreWithParentNode
WithoutparentNodes
incidence
childNode <- 5
# Identify the parent nodes for this child in the current DAG
parentNodes <- which(incidence[, childNode] == 1)
parentNodes
# Calculate the score for the child with all its current parents
scoreWithAllParents <- BiDAG:::DAGcorescore(childNode, parentnodes = parentNodes, scoreParam$n, scoreParam)
scoreWithAllParents
parentNode <- 3
if (parentNode != childNode) {
# Check if parentNode is actually a parent in this DAG
if (parentNode %in% parentNodes) {
# Remove parentNode and calculate the score
WithoutparentNodes <- parentNodes[!parentNodes == parentNode]
scoreWithoutParent <- BiDAG:::DAGcorescore(childNode, parentnodes = WithoutparentNodes, scoreParam$n, scoreParam)
# Calculate beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithAllParents - scoreWithoutParent
} else {
WithparentNodes <-c(parentNode, parentNodes)
scoreWithParentNode <- BiDAG:::DAGcorescore(childNode, parentnodes = WithparentNodes, scoreParam$n, scoreParam)
# Calculate the beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithParentNode - scoreWithAllParents
# Print the scoreWithParentNode
# print(paste("Child node",childNode,
#             " has parents:",paste(parentNodes, collapse = ", "),
#             " with Added node:",parentNode,
#             " scoreWithParentNode is", scoreWithParentNode,
#             " scoreWithAllParents is", scoreWithAllParents))
}
} else {
# Beta score is not applicable for self (node cannot be its own parent)
allBetaScores[parentNode, childNode, dagIndex] <- NA
}
WithoutparentNodes
scoreWithoutParent
allBetaScores[parentNode, childNode, dagIndex]
612.4991 - scoreWithoutParent
parentNode <- 6
if (parentNode != childNode) {
# Check if parentNode is actually a parent in this DAG
if (parentNode %in% parentNodes) {
# Remove parentNode and calculate the score
WithoutparentNodes <- parentNodes[!parentNodes == parentNode]
scoreWithoutParent <- BiDAG:::DAGcorescore(childNode, parentnodes = WithoutparentNodes, scoreParam$n, scoreParam)
# Calculate beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithAllParents - scoreWithoutParent
} else {
WithparentNodes <-c(parentNode, parentNodes)
scoreWithParentNode <- BiDAG:::DAGcorescore(childNode, parentnodes = WithparentNodes, scoreParam$n, scoreParam)
# Calculate the beta score
allBetaScores[parentNode, childNode, dagIndex] <- scoreWithParentNode - scoreWithAllParents
# Print the scoreWithParentNode
# print(paste("Child node",childNode,
#             " has parents:",paste(parentNodes, collapse = ", "),
#             " with Added node:",parentNode,
#             " scoreWithParentNode is", scoreWithParentNode,
#             " scoreWithAllParents is", scoreWithAllParents))
}
} else {
# Beta score is not applicable for self (node cannot be its own parent)
allBetaScores[parentNode, childNode, dagIndex] <- NA
}
allBetaScores[parentNode, childNode, dagIndex]
